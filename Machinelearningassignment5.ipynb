{
 "cells": [
  {
   "cell_type": "raw",
   "id": "39990e0b-315b-4b73-a6a2-c512c26eaf27",
   "metadata": {},
   "source": [
    "1=Data encoding refers to the process of converting categorical data (data that represents categories or labels) into a numerical format that can be used for analysis and modeling in data science. Categorical data is non-numeric and includes features like gender, color, country, and more. Since many machine learning algorithms and statistical techniques require numerical inputs, data encoding is necessary to represent categorical data in a way that these algorithms can process.\n",
    "\n",
    "There are different types of data encoding techniques used in data science:\n",
    "\n",
    "Label Encoding: Assigns a unique integer to each category. However, this can sometimes imply an ordinal relationship that may not exist in the data.\n",
    "\n",
    "One-Hot Encoding: Creates binary columns for each category, indicating the presence or absence of that category. This method prevents ordinal assumptions and works well for nominal categorical data.\n",
    "\n",
    "Ordinal Encoding: Assigns integer values to categories based on an ordered relationship. This is suitable when the categories have a meaningful order.\n",
    "\n",
    "Binary Encoding: Encodes categories into binary digits, which can reduce dimensionality while preserving the categorical information.\n",
    "\n",
    "Hash Encoding: Converts categories into hash values, which can be useful for handling high cardinality categorical variables.\n",
    "\n",
    "Importance of Data Encoding in Data Science:\n",
    "\n",
    "Compatibility: Many machine learning algorithms and models require numerical inputs. Data encoding converts categorical data into a format that can be used by these algorithms.\n",
    "\n",
    "Utilizing All Features: Without encoding, categorical data wouldn't be usable, leading to the loss of valuable information in feature-rich datasets.\n",
    "\n",
    "Avoiding Bias: Some algorithms might unintentionally assign different weights or meanings to different categories. Proper encoding ensures fair treatment of all categories.\n",
    "\n",
    "Feature Engineering: Data encoding is a crucial step in feature engineering, where you create new features or transform existing ones to improve model performance.\n",
    "\n",
    "Data Quality: Well-encoded data contributes to cleaner, more accurate analysis and modeling results.\n",
    "\n",
    "Interpretability: Encoded data can make it easier to interpret and visualize relationships between variables.\n",
    "\n",
    "Example: Data Encoding in Predicting Customer Churn:\n",
    "\n",
    "Consider a dataset for a telecom company's customer churn prediction. One feature is \"contract type,\" which can have values \"month-to-month,\" \"one year,\" and \"two years.\"\n",
    "\n",
    "Without encoding, machine learning algorithms wouldn't understand these values. By applying one-hot encoding, each contract type becomes a separate binary column: \"month-to-month,\" \"one year,\" and \"two years.\" The value 1 is assigned to the respective column when the contract type is present, and 0 when it's not.\n",
    "\n",
    "This transformation allows algorithms to process the data and identify relationships between contract type and churn. Additionally, it avoids creating a false ordinal relationship that could occur if we used label encoding.\n",
    "\n",
    "In essence, data encoding is essential for making categorical data useful in data analysis, machine learning, and statistical modeling, contributing to the accuracy and interpretability of results."
   ]
  },
  {
   "cell_type": "raw",
   "id": "c6d56519-bac6-4d53-8990-7c0e7d4a6749",
   "metadata": {},
   "source": [
    "2=Nominal encoding is a technique used to convert categorical data with nominal (unordered) categories into a numerical format that can be used for analysis and modeling. Nominal categories have no inherent order, and the primary goal of nominal encoding is to represent each category with a unique numerical value while avoiding the introduction of any ordinal relationships.\n",
    "\n",
    "One common method for nominal encoding is one-hot encoding, where each category is represented by a binary (0 or 1) column. Each column corresponds to a category, and a value of 1 indicates the presence of that category, while all other columns have a value of 0.\n",
    "\n",
    "Example: Nominal Encoding in a Real-World Scenario\n",
    "\n",
    "Scenario: Imagine you're working for an e-commerce company that sells clothing. You have a dataset of customer reviews for different types of clothing, and one of the categorical features is \"color,\" with categories such as \"red,\" \"blue,\" \"green,\" \"yellow,\" and \"black.\"\n",
    "\n",
    "Task: You want to perform sentiment analysis on customer reviews and predict whether a review is positive, negative, or neutral.\n",
    "\n",
    "Nominal Encoding Approach:\n",
    "Since the \"color\" feature is nominal (unordered), one-hot encoding is a suitable approach. You'll create a binary column for each color category. If a review mentions a specific color, the corresponding column will have a value of 1, and all other color columns will have a value of 0.\n",
    "\n",
    "Original Data (Partial):\n",
    "\n",
    "Review\tColor\n",
    "...\t...\n",
    "Good\tBlue\n",
    "Bad\tRed\n",
    "Neutral\tGreen\n",
    "...\t...\n",
    "After Nominal Encoding (Partial):\n",
    "\n",
    "Review\tColor_Blue\tColor_Red\tColor_Green\tColor_Yellow\tColor_Black\n",
    "...\t...\t...\t...\t...\t...\n",
    "Good\t1\t0\t0\t0\t0\n",
    "Bad\t0\t1\t0\t0\t0\n",
    "Neutral\t0\t0\t1\t0\t0\n",
    "...\t...\t...\t...\t...\t...\n",
    "Benefits of Nominal Encoding:\n",
    "\n",
    "Preserves Categorical Information: Nominal encoding transforms categorical data into a format that can be processed by algorithms while preserving the distinctness of categories.\n",
    "No Assumption of Order: Nominal encoding avoids introducing any ordinal relationships that may not exist among nominal categories.\n",
    "Applicability to Various Algorithms: Encoded data can be used with a wide range of machine learning algorithms.\n",
    "Considerations:\n",
    "\n",
    "For datasets with high cardinality (many unique categories), one-hot encoding can lead to high-dimensional data. In such cases, you might explore other encoding techniques or dimensionality reduction methods.\n",
    "In summary, nominal encoding, often accomplished through one-hot encoding, is a valuable technique for representing unordered categorical data in a way that is suitable for analysis, modeling, and machine learning applications."
   ]
  },
  {
   "cell_type": "raw",
   "id": "1ff432ca-8077-47e8-a2ee-5c81fca47f3a",
   "metadata": {},
   "source": [
    "3=Nominal encoding and one-hot encoding are both techniques used to represent categorical data in a numerical format for analysis and modeling. The choice between them depends on the nature of the categorical variable and the specific goals of the analysis. Nominal encoding is preferred over one-hot encoding when dealing with categorical variables that have a high cardinality (many unique categories) and where one-hot encoding could lead to high-dimensional data.\n",
    "\n",
    "Situation: High Cardinality Categorical Variables\n",
    "\n",
    "Example: Movie Genres\n",
    "Consider a dataset containing information about movies, including a categorical feature \"genre\" that represents different movie genres. The \"genre\" feature has a high cardinality because there are many unique genres, such as action, drama, comedy, horror, fantasy, science fiction, romance, and more.\n",
    "\n",
    "Challenge: One-hot encoding the \"genre\" feature would result in creating numerous binary columns, one for each genre. This could lead to a dataset with a large number of dimensions, making analysis and modeling computationally expensive and potentially causing the \"curse of dimensionality.\"\n",
    "\n",
    "Solution: In this scenario, nominal encoding would be preferred over one-hot encoding. Instead of creating separate binary columns for each genre, you could encode the genres using unique numerical codes. For instance, you might assign integers to each genre: 1 for action, 2 for drama, 3 for comedy, and so on.\n",
    "\n",
    "Original Data (Partial):\n",
    "\n",
    "Movie\tGenre\n",
    "Movie A\tAction\n",
    "Movie B\tDrama\n",
    "Movie C\tComedy\n",
    "Movie D\tHorror\n",
    "...\t...\n",
    "After Nominal Encoding (Partial):\n",
    "\n",
    "Movie\tEncoded_Genre\n",
    "Movie A\t1\n",
    "Movie B\t2\n",
    "Movie C\t3\n",
    "Movie D\t4\n",
    "...\t...\n",
    "Benefits:\n",
    "\n",
    "Reduced Dimensionality: Nominal encoding reduces the dimensionality of the dataset compared to one-hot encoding, making analysis and modeling more manageable.\n",
    "Avoiding High-Dimensional Data: High-dimensional data can lead to overfitting and computational inefficiencies, which nominal encoding helps mitigate.\n",
    "Considerations:\n",
    "\n",
    "Nominal encoding might introduce unintended ordinal relationships, so it's important to use it when the categories truly are nominal (unordered).\n",
    "The choice between nominal encoding and one-hot encoding depends on the specific characteristics of the data and the goals of the analysis."
   ]
  },
  {
   "cell_type": "raw",
   "id": "51296843-cbad-4ea6-a3e0-de0baf88d2b5",
   "metadata": {},
   "source": [
    "4=If the dataset contains categorical data with 5 unique values, I would typically use one-hot encoding to transform this data into a format suitable for machine learning algorithms. One-hot encoding is particularly well-suited when dealing with a small number of unique categorical values.\n",
    "\n",
    "Explanation:\n",
    "\n",
    "One-hot encoding creates binary columns for each category, indicating the presence or absence of that category. Each unique value is represented by a separate binary column, and a value of 1 is assigned to the column corresponding to the category, while all other columns have a value of 0. This technique ensures that there is no implied ordinal relationship between the categories, which is especially important for nominal categorical data.\n",
    "\n",
    "Here's why one-hot encoding is a suitable choice for this scenario:\n",
    "\n",
    "Preservation of Information: One-hot encoding preserves all the information associated with the categorical values. Each unique value gets its own distinct column, ensuring that no information is lost during the encoding process.\n",
    "\n",
    "No Ordinal Assumptions: One-hot encoding avoids introducing any ordinal relationships that may not exist among the categories. This is essential when dealing with nominal categorical data.\n",
    "\n",
    "Suitable for Small Cardinality: One-hot encoding works well for datasets with a small number of unique values, as each category gets a dedicated binary column, and the increase in dimensionality is manageable.\n",
    "\n",
    "Algorithm Compatibility: Many machine learning algorithms and models can handle one-hot encoded data. It allows algorithms to treat each category independently without assuming any numerical relationships.\n",
    "\n",
    "Interpretability: One-hot encoding results in easily interpretable features. The presence or absence of a category in a binary column directly represents that category's contribution to the data point.\n",
    "\n",
    "Example: Categorical Feature \"Color\"\n",
    "\n",
    "Suppose you have a dataset with a categorical feature \"color\" that can take on five unique values: red, blue, green, yellow, and black. One-hot encoding would create five binary columns, one for each color. For example, a data point with the color \"blue\" would have a value of 1 in the \"Color_Blue\" column and 0 in all other color columns.\n",
    "\n",
    "In this scenario, one-hot encoding is a suitable choice because it accurately represents the categorical nature of the data, avoids introducing order, and is compatible with a small number of unique values."
   ]
  },
  {
   "cell_type": "raw",
   "id": "b44f5fef-bc6c-49c2-9c08-a7a2e4eeb7f5",
   "metadata": {},
   "source": [
    "5=If you were to use nominal encoding (specifically, one-hot encoding) to transform the categorical data in a dataset with 1000 rows and 5 columns, you would create a new binary column for each unique value in the categorical columns. The number of new columns created would depend on the number of unique values in each categorical column.\n",
    "\n",
    "Since you have two categorical columns, let's consider the number of unique values in each of these columns and calculate the total number of new columns that would be created.\n",
    "\n",
    "Let's assume the following:\n",
    "\n",
    "The first categorical column has 4 unique values.\n",
    "The second categorical column has 6 unique values.\n",
    "For each unique value in each categorical column, a new binary column would be created. Therefore, the total number of new columns created would be:\n",
    "\n",
    "Number of new columns = (Number of unique values in categorical column 1) + (Number of unique values in categorical column 2)\n",
    "= 4 + 6\n",
    "= 10\n",
    "\n",
    "So, if you were to use nominal encoding (one-hot encoding) to transform the categorical data in this dataset, you would create a total of 10 new columns. Each unique value in the categorical columns would result in a separate binary column after one-hot encoding."
   ]
  },
  {
   "cell_type": "raw",
   "id": "4a8ef75c-6b83-4c23-8344-014f089459ac",
   "metadata": {},
   "source": [
    "6=In a dataset containing information about different types of animals, including their species, habitat, and diet, the most suitable encoding technique to transform the categorical data into a format suitable for machine learning algorithms would be a combination of one-hot encoding and label encoding, depending on the nature of the categorical variables.\n",
    "\n",
    "Species: Since the \"species\" is a nominal categorical variable with no inherent order, one-hot encoding would be the preferred approach. One-hot encoding would create separate binary columns for each unique species, indicating the presence or absence of that species.\n",
    "\n",
    "Habitat: The \"habitat\" variable could be either ordinal or nominal, depending on whether there is an inherent order to the different habitats. If there's an order (e.g., \"forest\" < \"grassland\" < \"desert\"), you might consider label encoding. However, if there's no meaningful order, one-hot encoding is a better choice to preserve the nominal nature of the data and avoid introducing unintended ordinal relationships.\n",
    "\n",
    "Diet: Similar to \"habitat,\" the \"diet\" variable could be ordinal or nominal, depending on the nature of the categories. If the diet categories have a meaningful order (e.g., \"carnivore\" < \"herbivore\" < \"omnivore\"), you might consider label encoding. Otherwise, one-hot encoding is preferred.\n",
    "\n",
    "Justification:\n",
    "\n",
    "Preservation of Information: Both one-hot encoding and label encoding preserve the information contained in the categorical variables, ensuring that no valuable data is lost during encoding.\n",
    "\n",
    "Appropriate Handling of Ordinality: Label encoding is suitable when there is a clear ordinal relationship between categories. One-hot encoding, on the other hand, is better for nominal variables to avoid introducing unintended ordinal relationships.\n",
    "\n",
    "Algorithm Compatibility: Most machine learning algorithms can handle one-hot encoded data. One-hot encoding ensures that the algorithm treats each category independently without assuming numerical relationships.\n",
    "\n",
    "Avoiding Bias: One-hot encoding prevents any algorithmic bias that might arise from assigning arbitrary numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f90a66d5-165c-434e-a86e-703da0b84ffe",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate object of type '<class 'numpy.ndarray'>'; only Series and DataFrame objs are valid",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 35\u001b[0m\n\u001b[1;32m     28\u001b[0m numerical_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m\"\u001b[39m: age_data,\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmonthly_charges\u001b[39m\u001b[38;5;124m\"\u001b[39m: monthly_charges_data,\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtenure\u001b[39m\u001b[38;5;124m\"\u001b[39m: tenure_data\n\u001b[1;32m     32\u001b[0m })\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Concatenate the encoded and numerical features\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m encoded_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnumerical_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_hot_encoded_gender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoded_contract_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/reshape/concat.py:368\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconcat\u001b[39m(\n\u001b[1;32m    148\u001b[0m     objs: Iterable[NDFrame] \u001b[38;5;241m|\u001b[39m Mapping[HashableT, NDFrame],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    157\u001b[0m     copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    158\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03m    Concatenate pandas objects along a particular axis.\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m    1   3   4\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 368\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/reshape/concat.py:458\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, (ABCSeries, ABCDataFrame)):\n\u001b[1;32m    454\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    455\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot concatenate object of type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    456\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly Series and DataFrame objs are valid\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    457\u001b[0m         )\n\u001b[0;32m--> 458\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m    460\u001b[0m     ndims\u001b[38;5;241m.\u001b[39madd(obj\u001b[38;5;241m.\u001b[39mndim)\n\u001b[1;32m    462\u001b[0m \u001b[38;5;66;03m# get the sample\u001b[39;00m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;66;03m# want the highest ndim that we have, and must be non-empty\u001b[39;00m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;66;03m# unless all objs are empty\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot concatenate object of type '<class 'numpy.ndarray'>'; only Series and DataFrame objs are valid"
     ]
    }
   ],
   "source": [
    "#7=\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Sample data\n",
    "contract_type = [\"month-to-month\", \"one year\", \"two year\"]\n",
    "\n",
    "# Create a label encoder instance\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the data\n",
    "encoded_contract_type = label_encoder.fit_transform(contract_type)\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "gender_data = [\"male\", \"female\", \"male\", \"female\", \"male\"]\n",
    "\n",
    "# Create a DataFrame\n",
    "data = pd.DataFrame({\"gender\": gender_data})\n",
    "\n",
    "# Perform one-hot encoding\n",
    "one_hot_encoded_gender = pd.get_dummies(data[\"gender\"], prefix=\"gender\")\n",
    "# Sample data\n",
    "age_data = [30, 45, 25, 60, 35]\n",
    "monthly_charges_data = [50, 70, 40, 80, 60]\n",
    "tenure_data = [12, 24, 6, 36, 18]\n",
    "\n",
    "# Create a DataFrame for numerical features\n",
    "numerical_data = pd.DataFrame({\n",
    "    \"age\": age_data,\n",
    "    \"monthly_charges\": monthly_charges_data,\n",
    "    \"tenure\": tenure_data\n",
    "})\n",
    "\n",
    "# Concatenate the encoded and numerical features\n",
    "encoded_data = pd.concat([numerical_data, one_hot_encoded_gender, encoded_contract_type], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02422b0-19f9-459c-9ddc-5ced96d35d99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
